{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e9b9e34",
   "metadata": {},
   "source": [
    "# Exam Score Predictor Using Decision Tree Regression\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates a machine learning approach to predict student exam scores based on various factors including study hours, sleep patterns, attendance, and previous academic performance. We'll use a Decision Tree Regressor from scikit-learn to build our predictive model.\n",
    "\n",
    "## Project Goals\n",
    "- Load and explore student performance data\n",
    "- Build a Decision Tree Regression model\n",
    "- Train the model on historical student data\n",
    "- Make predictions and compare them with actual scores\n",
    "- Evaluate model performance\n",
    "\n",
    "## What is Decision Tree Regression?\n",
    "Decision Tree Regression is a supervised machine learning algorithm that predicts continuous values (like exam scores) by learning decision rules from the training data. The model creates a tree-like structure where each internal node represents a \"test\" on a feature (e.g., hours studied > 5), each branch represents the outcome of the test, and each leaf node represents a prediction value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea95bd0",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries\n",
    "\n",
    "We begin by importing the necessary Python libraries for our machine learning project:\n",
    "\n",
    "- **pandas**: A powerful data manipulation library that provides data structures like DataFrames for handling structured data (like CSV files)\n",
    "- **DecisionTreeRegressor**: A machine learning algorithm from scikit-learn's tree module that predicts continuous values using a decision tree structure\n",
    "\n",
    "These libraries form the foundation of our predictive modeling workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7e14ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Modules\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor as DTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27be1fe",
   "metadata": {},
   "source": [
    "## Step 2: Load the Dataset\n",
    "\n",
    "In this step, we load our student exam score data from a CSV (Comma-Separated Values) file:\n",
    "\n",
    "### What's happening here:\n",
    "1. **File Path Definition**: We specify the absolute path to our CSV file containing student data\n",
    "2. **Data Loading**: Using pandas' `read_csv()` function, we read the CSV file into a DataFrame object\n",
    "3. **Confirmation Message**: We print a success message to confirm the data has been loaded\n",
    "\n",
    "### About the Dataset:\n",
    "The CSV file contains student information including:\n",
    "- `student_id`: Unique identifier for each student\n",
    "- `hours_studied`: Number of hours spent studying\n",
    "- `sleep_hours`: Average hours of sleep per night\n",
    "- `attendance_percent`: Class attendance percentage\n",
    "- `previous_scores`: Scores from previous exams\n",
    "- `exam_score`: The actual exam score (our target variable)\n",
    "\n",
    "**Note**: If you're running this notebook, you may need to update the file path to match your local directory structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0a7244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather Data from file\n",
    "# Load CSV File\n",
    "scoresFilepath = \"/home/jha/MLLearning/exam-score-predictor/student_exam_scores.csv\"\n",
    "\n",
    "# Read the file\n",
    "score_data = pd.read_csv(scoresFilepath)\n",
    "print(\"Completed loading data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6fcdb6",
   "metadata": {},
   "source": [
    "## Step 3: Prepare Features and Target Variable\n",
    "\n",
    "This is a crucial step in machine learning where we separate our data into features (input variables) and target (what we want to predict):\n",
    "\n",
    "### Target Variable (y):\n",
    "- **`y = score_data.exam_score`**: We extract the 'exam_score' column as our target variable\n",
    "- This is what we want our model to learn to predict\n",
    "- In machine learning terminology, this is often called the \"dependent variable\" or \"label\"\n",
    "\n",
    "### Feature Variables (Xa):\n",
    "- **`dataPoints`**: A list defining which columns to use as input features\n",
    "- We've selected four features that logically influence exam performance:\n",
    "  - `hours_studied`: More study time typically leads to better scores\n",
    "  - `sleep_hours`: Adequate sleep affects cognitive function and test performance\n",
    "  - `attendance_percent`: Regular attendance correlates with better understanding\n",
    "  - `previous_scores`: Past performance is often a good predictor of future performance\n",
    "- **`Xa = score_data[dataPoints]`**: We create a new DataFrame containing only these feature columns\n",
    "\n",
    "### Why this matters:\n",
    "The quality and relevance of features you choose significantly impact model performance. These features were selected because they have a logical relationship with exam scores and provide diverse information about student behavior and preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e80a558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Variables\n",
    "y = score_data.exam_score\n",
    "dataPoints = [\"hours_studied\", \"sleep_hours\", \"attendance_percent\", \"previous_scores\"]\n",
    "Xa = score_data[dataPoints]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9424766a",
   "metadata": {},
   "source": [
    "## Step 4: Initialize the Decision Tree Model\n",
    "\n",
    "Here we create our machine learning model by instantiating a Decision Tree Regressor:\n",
    "\n",
    "### Model Configuration:\n",
    "- **`DTS(random_state=1)`**: Creates a new Decision Tree Regressor object\n",
    "- **`random_state=1`**: This is a critical parameter that ensures reproducibility\n",
    "\n",
    "### What is random_state?\n",
    "Decision trees involve some randomness in how they're built. By setting `random_state=1`, we:\n",
    "- Ensure the model produces the same results every time we run the code\n",
    "- Make our work reproducible for ourselves and others\n",
    "- Enable fair comparisons when testing different approaches\n",
    "\n",
    "Think of `random_state` as a seed value - like a starting point for random number generation. Using the same seed always produces the same sequence of \"random\" decisions.\n",
    "\n",
    "### At this stage:\n",
    "The model is just an empty template - it hasn't learned anything yet. It's like having a blank notebook ready to be filled with knowledge. The actual learning happens in the next step during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade9ff57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Modeling\n",
    "score_model = DTS(random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1759df",
   "metadata": {},
   "source": [
    "## Step 5: Train the Model\n",
    "\n",
    "This is where the actual machine learning happens! We train our model using the `.fit()` method:\n",
    "\n",
    "### What happens during training:\n",
    "- **`score_model.fit(Xa, y)`**: This method trains the model by showing it examples\n",
    "- The model analyzes the relationship between features (Xa) and outcomes (y)\n",
    "- It learns patterns like: \"Students who study 8+ hours and attend 90%+ of classes tend to score higher\"\n",
    "\n",
    "### The Learning Process:\n",
    "1. **Decision Tree Building**: The algorithm creates a tree structure by:\n",
    "   - Finding the most informative feature to split on first\n",
    "   - Recursively splitting the data based on feature values\n",
    "   - Creating leaf nodes that contain predicted values\n",
    "\n",
    "2. **Pattern Recognition**: The tree learns rules like:\n",
    "   - \"If hours_studied > 7.5 AND previous_scores > 80, predict high score\"\n",
    "   - \"If attendance_percent < 60, predict lower score\"\n",
    "\n",
    "3. **Internal Optimization**: The algorithm determines:\n",
    "   - Which features are most important\n",
    "   - What threshold values to use for splitting\n",
    "   - How deep the tree should grow\n",
    "\n",
    "### After Training:\n",
    "Once training is complete, the model has \"learned\" from the data and is ready to make predictions on new examples. We confirm successful training with a message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353ca3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Model\n",
    "score_model.fit(Xa, y)\n",
    "print(\"\\nModel trained successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef26f44",
   "metadata": {},
   "source": [
    "## Step 6: Make Predictions\n",
    "\n",
    "Now that our model is trained, we can use it to make predictions:\n",
    "\n",
    "### What's happening:\n",
    "- **`score_model.predict(Xa)`**: We pass our feature data through the trained model\n",
    "- The model uses the decision tree it built during training to predict exam scores\n",
    "- **`predictions`**: This variable stores all the predicted scores as a NumPy array\n",
    "\n",
    "### How prediction works:\n",
    "For each student, the model:\n",
    "1. Takes their feature values (hours studied, sleep hours, etc.)\n",
    "2. Traverses the decision tree based on these values\n",
    "3. Follows the branches based on conditions learned during training\n",
    "4. Reaches a leaf node that contains the predicted exam score\n",
    "\n",
    "### Important Note:\n",
    "In this example, we're predicting on the same data we trained on (Xa). This is useful for:\n",
    "- Demonstrating how the model works\n",
    "- Checking if the model learned the training data patterns\n",
    "- Initial validation of model functionality\n",
    "\n",
    "**However**, in real-world applications, you should:\n",
    "- Split data into training and testing sets\n",
    "- Evaluate on unseen test data to assess true model performance\n",
    "- Avoid overfitting by not testing on training data\n",
    "\n",
    "This approach here is called \"in-sample prediction\" and gives us an optimistic view of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefac638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions!!!!\n",
    "predictions = score_model.predict(Xa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e08358",
   "metadata": {},
   "source": [
    "## Step 7: Display Results - Compare Predictions vs Actual Scores\n",
    "\n",
    "In this final step, we create a formatted table to compare our model's predictions against actual exam scores:\n",
    "\n",
    "### Output Formatting:\n",
    "- **Header Creation**: We use string formatting to create a professional-looking table\n",
    "  - `\"=\"*60`: Creates a line of 60 equal signs for visual separation\n",
    "  - `f\"{'Student ID':<15}\"`: Left-aligns text in a 15-character wide column\n",
    "  - The `<` symbol means left-align, and the number specifies column width\n",
    "\n",
    "### The Loop Iteration:\n",
    "```python\n",
    "for i in range(len(predictions)):\n",
    "```\n",
    "- Loops through each student (from index 0 to the last prediction)\n",
    "- `len(predictions)` gives us the total number of students\n",
    "\n",
    "### Data Extraction:\n",
    "For each iteration, we extract:\n",
    "1. **`student_id`**: Retrieved from the DataFrame using `.iloc[i]` (gets row by index)\n",
    "2. **`predicted`**: The model's prediction from our predictions array\n",
    "3. **`actual`**: The true exam score from our target variable (y)\n",
    "\n",
    "### Display Format:\n",
    "- **`.2f`**: Formats numbers to 2 decimal places for readability\n",
    "- Each row shows: Student ID | Predicted Score | Actual Score\n",
    "- This allows easy visual comparison of model accuracy\n",
    "\n",
    "### What to look for in the results:\n",
    "- **Close matches**: Predicted ≈ Actual indicates good model performance\n",
    "- **Large differences**: May reveal students with unusual patterns\n",
    "- **Consistent patterns**: If predictions are always too high/low, the model may have bias\n",
    "- **Overall accuracy**: Average difference between predicted and actual scores\n",
    "\n",
    "This comparison helps us understand:\n",
    "- How well our model performs\n",
    "- Whether it's making reasonable predictions\n",
    "- Which students' scores are harder to predict (potential outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff2a2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print each student's ID, predicted score, and actual score\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"{'Student ID':<15} {'Predicted Score':<20} {'Actual Score':<15}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    student_id = score_data.iloc[i]['student_id']\n",
    "    predicted = predictions[i]\n",
    "    actual = y.iloc[i]\n",
    "    print(f\"{student_id:<15} {predicted:<20.2f} {actual:<15.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72636c3",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "### What we accomplished:\n",
    "1. ✅ Loaded student exam data from a CSV file\n",
    "2. ✅ Prepared features and target variables for machine learning\n",
    "3. ✅ Built and trained a Decision Tree Regression model\n",
    "4. ✅ Generated predictions for student exam scores\n",
    "5. ✅ Compared predictions against actual scores\n",
    "\n",
    "### Model Limitations:\n",
    "- **In-sample prediction**: We tested on the same data we trained on, which doesn't reflect real-world performance\n",
    "- **No validation metrics**: We didn't calculate formal metrics like RMSE, MAE, or R²\n",
    "- **No train-test split**: A proper evaluation would use separate data for testing\n",
    "- **No hyperparameter tuning**: Default Decision Tree settings may not be optimal\n",
    "\n",
    "### Potential Improvements:\n",
    "1. **Train-Test Split**: Divide data into 80% training, 20% testing for unbiased evaluation\n",
    "2. **Cross-Validation**: Use k-fold cross-validation for robust performance estimates\n",
    "3. **Feature Engineering**: Create new features (e.g., study_to_sleep_ratio)\n",
    "4. **Model Evaluation Metrics**:\n",
    "   - Mean Absolute Error (MAE): Average prediction error\n",
    "   - Root Mean Squared Error (RMSE): Penalizes larger errors more\n",
    "   - R² Score: Proportion of variance explained\n",
    "5. **Hyperparameter Tuning**: Optimize tree depth, min_samples_split, etc.\n",
    "6. **Model Comparison**: Try other algorithms (Random Forest, Linear Regression, XGBoost)\n",
    "7. **Feature Importance**: Analyze which features matter most\n",
    "8. **Visualization**: Plot actual vs predicted scores, feature distributions, tree structure\n",
    "\n",
    "### Key Takeaways:\n",
    "- Decision Trees are interpretable models that learn non-linear relationships\n",
    "- Feature selection significantly impacts prediction quality\n",
    "- Model evaluation should always be done on unseen data\n",
    "- Real-world applications require more rigorous validation and testing\n",
    "\n",
    "This notebook provides a foundation for understanding machine learning workflows. The methodology demonstrated here can be extended and refined for more sophisticated predictive modeling projects."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
